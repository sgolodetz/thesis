\chapter{Design}

Given enough time -- in practice, several hours for a series of images -- segmentation and feature identification are both tasks that can be performed manually, and to a high standard, by a radiologist. It is therefore sensible for a computerised segmentation system to focus on the goal of making this process faster, whilst engendering a minimal loss of accuracy when compared to the `gold standard' manual alternative. It is not desirable to fully automate such a system, to the extent that a radiologist can no longer see (and therefore trust) what it is doing; it is, however, desirable to minimise the interactivity burden on the end user. It could be argued that \emph{a system should minimise the level of interaction necessary whilst maximising the level of interaction possible}. This allows a radiologist to segment an image series quickly, without sacrificing the opportunity to verify (and, if necessary, modify) the end results.

The \emph{Centipede} Toolkit, my computerised implementation of the research described in this thesis, was designed very much with this principle in mind. Although they can be made to produce excellent results, many approaches to segmentation require a large number of different parameters that have to be `tweaked' by the end user: this customisability can be desirable, but comes at an obvious price. Simple algorithms such as binary thresholding may require only one or two parameters, which present only a small burden to the user, but more sophisticated algorithms can require a larger number of parameters, not all of them intuitive. For example, the process necessary when using the \emph{geodesic active contours} level set algorithm in the widely-used (and excellent) Insight Toolkit \cite{?} requires at least 4 parameters (the relative scalings of the terms in the PDE  and the $\alpha$ and $\beta$ values for the sigmoid filter), not including at least $1$ seed point, that must be set quite precisely on a per-image basis to obtain the desired results.

By contrast, the watershed/waterfall approach \cite{?} described in Chapter~\ref{?} requires far less input from the user. Because it produces a global segmentation of the image, it requires no seed points (as we are not trying to segment any particular feature). Whilst the preprocessing steps required to produce the watershed input image generally require some parameters to control the smoothing of the original image, experience has shown that good results are obtained without the need to vary these on a per-image basis (see Chapter~\ref{?}). The watershed/waterfall approach thus fulfils the first criterion specified above, namely that of minimising the necessary level of interaction.

The basic watershed/waterfall approach, however, is in some ways a victim of its own automation. Its lack of large numbers of parameters, whilst a blessing to the end user, is also problematic when the produced segmentation is not precisely what was wanted. It provides a segmentation process driven entirely by grey levels in the original image and independent of important anatomical knowledge. TODO