\chapter{Design}

Given enough time -- in practice, several hours for a series of images -- segmentation and feature identification are both tasks that can be performed manually, and to a high standard, by a radiologist. It is therefore sensible for a computerised segmentation system to focus on the goal of making this process faster, whilst engendering a minimal loss of accuracy when compared to the `gold standard' manual alternative. It is not desirable to fully automate such a system, to the extent that a radiologist can no longer see (and therefore trust) what it is doing; it is, however, desirable to minimise the interactivity burden on the end user. It could be argued that \emph{a system should minimise the level of interaction necessary whilst maximising the level of interaction possible}. This allows a radiologist to segment an image series quickly, without sacrificing the opportunity to verify (and, if necessary, modify) the end results.

Although they can be made to produce excellent results, many existing approaches to segmentation require a large number of different parameters that have to be `tweaked' by the end user: this customisability can be desirable, but comes at an obvious price. In terms of the criteria just mentioned, it could be argued that such algorithms place the emphasis on maximising the level of interaction possible, at the expense of not minimising the interaction necessary. Simple algorithms such as binary thresholding may require only one or two intuitive parameters, which present only a small burden to the user, but more sophisticated algorithms can require a larger number of parameters, not all of them intuitive. For example, the process necessary when using the \emph{geodesic active contours} level set algorithm in the widely-used (and excellent) Insight Toolkit \cite{?} requires at least 4 parameters (the relative scalings of the terms in the PDE  and the $\alpha$ and $\beta$ values for the sigmoid filter), not including at least $1$ seed point, that must be set quite precisely on a per-image basis to obtain the desired results. For my own research, I chose to focus on algorithms which required fewer parameters to be modified per-image. These tend to suffer from the opposite problem: they minimise the level of interaction necessary at the expense of not maximising the interaction possible. Finding ways to allow users to interact with the segmentations produced by these sort of methods seemed like a promising avenue for research.

A suitable method which requires very little input from the user is the watershed/waterfall approach \cite{?} described in Chapter~\ref{?}. Because it produces a global segmentation of the image, it requires no seed points (as we are not trying to segment any particular feature). Furthermore, whilst the preprocessing steps required to produce the watershed input image generally require some parameters to control the smoothing of the original image, experience has shown that good results are obtained without the need to vary these on a per-image basis (see Chapter~\ref{chap:segmentation}). The approach thus succeeds in minimising the level of user interaction necessary.

The basic watershed/waterfall approach, however, is in some ways a victim of its own automation. Its lack of large numbers of parameters, whilst a blessing to the end user, is also problematic when the produced segmentation is not precisely what was wanted. It provides a segmentation process driven entirely by grey levels in the original image and independent of important anatomical knowledge. TODO

\iffalse

The \emph{Centipede} Toolkit, my computerised implementation of the research described in this thesis, was designed very much with this principle in mind. Although they can be made to produce excellent results, many approaches to segmentation require a large number of different parameters that have to be `tweaked' by the end user: this customisability can be desirable, but comes at an obvious price. Simple algorithms such as binary thresholding may require only one or two parameters, which present only a small burden to the user, but more sophisticated algorithms can require a larger number of parameters, not all of them intuitive. For example, the process necessary when using the \emph{geodesic active contours} level set algorithm in the widely-used (and excellent) Insight Toolkit \cite{?} requires at least 4 parameters (the relative scalings of the terms in the PDE  and the $\alpha$ and $\beta$ values for the sigmoid filter), not including at least $1$ seed point, that must be set quite precisely on a per-image basis to obtain the desired results.

By contrast, the watershed/waterfall approach \cite{?} described in Chapter~\ref{?} requires far less input from the user. Because it produces a global segmentation of the image, it requires no seed points (as we are not trying to segment any particular feature). Whilst the preprocessing steps required to produce the watershed input image generally require some parameters to control the smoothing of the original image, experience has shown that good results are obtained without the need to vary these on a per-image basis (see Chapter~\ref{?}). The watershed/waterfall approach thus fulfils the first criterion specified above, namely that of minimising the necessary level of interaction.

The basic watershed/waterfall approach, however, is in some ways a victim of its own automation. Its lack of large numbers of parameters, whilst a blessing to the end user, is also problematic when the produced segmentation is not precisely what was wanted. It provides a segmentation process driven entirely by grey levels in the original image and independent of important anatomical knowledge. For this reason, part of my research (see Chapter~\ref{chap:regionanalysis}) has been to show that such anatomical knowledge can be incorporated into a watershed/waterfall-generated segmentation \emph{post facto}.

The waterfall algorithm (see Chapter~\ref{?}) naturally produces a sequence of partitions of an image, together with region adjacency information for each partition. These partitions are produced in order of increasing coarseness/decreasing region count. The input to the waterfall algorithm is the fine partition produced by the watershed transform; subsequent partitions are obtained by iterating what is essentially a carefully-designed region merging process. The final theoretical partition has exactly one region, namely the whole image, although it is evidently possible (and sometimes desirable, since the final partitions can be of little interest) to terminate the algorithm earlier if desired. As a result of the way the partitions were generated (by region merging), they can naturally be viewed as a hierarchy, in the sense that if several regions $r_1,\ldots,r_n$ in partition $i$ are merged into a single region $r'$ in partition $i+1$, then they can naturally be seen as the children of $r'$ in a hierarchy whose nodes represent regions, where each layer in the hierarchy represents one partition in the waterfall sequence (see Figure~\ref{?}). If the waterfall process was continued until the final possible partition, then this hierarchy will initially be a tree (whose root represents the entire image), but more generally (and, in particular, once we start modifying the hierarchy) we will be dealing with a forest.

In Chapter~\ref{chap:regionanalysis}, I will demonstrate that it is possible to incorporate anatomical knowledge into the segmentation by modifying the generated partition forest for an image, thus allowing the user to correct the produced segmentation in cases where it would otherwise fail to reflect the underlying anatomy of the patient. This goes a significant way to fulfilling the second criterion outlined above, that of maximising the level of interaction possible.

\fi