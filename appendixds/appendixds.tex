\chapter{Data Structures}
\label{chap:appendixds}

%##################################################################################################
\section{Disjoint Set Forests}
%##################################################################################################

Echoing the more general definition of partitioning in Chapter~\ref{chap:ipfs}, we first observe that:

\begin{definition}
A set of k subsets $\{S'_1,\ldots,S'_k\}$ \textbf{partitions} a set $S$ iff:

\begin{enumerate}
\item $\bigcup_i S'_i = S$ and
\item $\forall i,j \cdot i \ne j \Rightarrow S'_i \cap S'_j = \emptyset$.
\end{enumerate}

\noindent (In words, the subsets together make up $S$, and are mutually disjoint.)
\end{definition}

\noindent \textbf{Disjoint set forests}, which are a staple of undergraduate computer science courses \cite{worrell06}, are a data structure designed to represent such a partition using a collection of trees, one for each subset (see Figure~\ref{?}). Each subset has a \emph{representative element}, namely the root node of its tree. The goal is to efficiently support three key operations:
%
\begin{enumerate}

\item MAKE-SET, which makes a subset containing a single element.
\item FIND-SET, which allows the lookup of the representative element of the subset containing a particular element.
\item UNION, which allows the (distinct) subsets containing two individual elements to be merged.

\end{enumerate}
%
The basic idea (initially ignoring the details) is that MAKE-SET makes a single node tree, FIND-SET follows the path from a given element to the top of its tree and returns the root, and UNION merges trees by making the root of one the child of the root of the other (see Figure~\ref{?}). However, in order to make things more efficient, two optimizations are commonly employed:
%
\begin{enumerate}

\item Rather than arbitrarily choosing which tree root should be the child of the other, the \textbf{union-by-rank} approach aims to approximate the ideal that when a UNION takes place, the root of the tree representing the smaller subset becomes the child of the root of the tree representing the larger subset, and not the other way round. This is sensible, because the alternative leads to trees of greater height, making FIND-SET operations more costly. However, rather than maintaining the actual size of each subset, which would necessitate more work, union-by-rank works by giving each node a \emph{rank} (which is maintained as an upper bound on the height of the node from the bottom of its tree) and making the root with the smaller rank the child of the root with the larger rank.

\item It is better to have short paths from each node to the root of its tree, because it makes FIND-SET operations more efficient. The \textbf{path compression} approach takes advantage of the walking up the tree done during FIND-SET operations to set the parent links of visited nodes to point directly to the tree root. This makes future FIND-SET operations more efficient (see Figure~\ref{?}).

\end{enumerate}

\noindent Bearing these optimizations in mind, the operations can then be implemented as shown in Listing~\ref{code:appendixds-dsf} (note that the names have been changed to match those in earlier listings, but the operations are exactly the same). The code itself is largely identical to the implementations originally given in \cite{worrell06}, but is slightly adapted to additionally support the storage of auxiliary data with each node. An example sequence of disjoint set operations is illustrated in Figure~\ref{?}.

%---
\begin{stulisting}[p]
\caption{Disjoint Set Forest Implementation}
\label{code:appendixds-dsf}
\lstinputlisting[style=Default]{appendixds/appendixds-dsf.lst}
\end{stulisting}
%---

%It can be shown, as per \cite{worrell06}, that `a sequence of $m$ MAKE-SET, UNION operations, $n$ of which are MAKE-SET operations, takes time $O(m \lg^* n)$ in the worst case'. Since $\lg^* n$ is incredibly slowly growing ($\le 5$ for any sensible $n$), the intuition is thus that such a sequence takes effectively $O(m)$ time in practice. Thus each individual operation is almost amortized constant time, and the goal of making the operations efficient is achieved.

\afterpage{\clearpage}
\newpage

%##################################################################################################
\section{Minimum Spanning Trees}
%##################################################################################################

From basic graph theory, recall that given a positively-weighted, undirected graph $G = (V,E,w)$ with vertex set $V$, edge set $E$ and weight function $w: E \times E \to \mathbb{R}^+$, we say that $T$ is a (there can be more than one possibility) minimum spanning tree (MST) for $G$ iff:
%
\begin{enumerate}
\item $T$ is a \emph{tree}, i.e.~$T$ is a connected, acyclic graph.
\item $T$ \emph{spans} $G$, i.e.~$T$'s vertex set is also $V$.
\item $T$ is of \emph{minimum weight}, i.e.~there is no spanning tree of $G$ whose edge weights sum to a strictly lesser value than the edge weights of $T$.
\end{enumerate}
%
For our purposes here, we build on this definition to define a \emph{rooted MST}, which is just an MST with a defined root node (this is the type of MST used by the waterfall algorithms described in Chapter~\ref{chap:segmentation}). In implementation terms, this makes a significant difference, because we can then assign each vertex a parent and then traverse the tree in the usual recursive manner (with an unrooted tree, we have to treat the tree as a graph, which complicates the algorithms somewhat).

%################################################
\subsection{Construction}
%################################################

%---
\begin{stulisting}[p]
\caption{Rooted MST Construction}
\label{code:appendixds-rootedmst-construction}
\lstinputlisting[style=Default]{appendixds/appendixds-rootedmst-construction.lst}
\end{stulisting}
%---

There are several algorithms for constructing normal MSTs of graphs, the best-known of which are perhaps Kruskal's algorithm (which sorts the edges in non-decreasing order of weight and then adds edges -- starting from the one with the smallest weight -- that do not create a cycle until all the vertices have been spanned) and Prim's algorithm (which maintains a set of spanned vertices -- initially an arbitrary start vertex -- and then repeatedly adds the smallest edge that connects a currently unspanned vertex to the vertices in this set until all the vertices have been spanned).

To construct a \emph{rooted} MST, however, Prim's algorithm is superior to Kruskal's, because it works by gradually expanding a tree, starting from an initial vertex -- this can be easily adapted to build a rooted MST by choosing the initial vertex to be the root. A suitable implementation is shown in Listing~\ref{code:appendixds-rootedmst-construction}. This represents the tree using an adjacency graph (referred to using \texttt{base()} in the code) that stores parent pointers at each vertex. Constructing a rooted MST using Kruskal's algorithm would involve far more work, because Kruskal's adds edges all over the graph and only guarantees to join them up by the time the algorithm terminates.

\afterpage{\clearpage}

%################################################
\subsection{Node Merging}
%################################################

%---
\begin{stulisting}[p]
\caption{Merging Nodes in a Rooted MST}
\label{code:appendixds-rootedmst-mergenodes}
\lstinputlisting[style=Default]{appendixds/appendixds-rootedmst-mergenodes.lst}
\end{stulisting}
%---

For rooted MSTs to be used as the underlying data structure for the various waterfall algorithms, they need to be augmented with a \emph{node merging} operation (see Listing~\ref{code:appendixds-rootedmst-mergenodes}). Since we're dealing with a rooted tree, the only nodes which can merge must form a parent/child pair in the tree. The basic algorithm is simple (remove one of the nodes and move its children across to the other one), but in practice things are slightly more complicated.

The first step is to pick which node should survive and which should be removed. In the implementation here, the lower-indexed node is retained, because the rooted MSTs are being used in the construction of partition forests, which assign nodes an index corresponding to the lowest-indexed pixel they contain. Other implementations might want/need to make a different choice here.

The next step depends on whether we are retaining the parent of the pair being merged, or the child. If we are retaining the parent, we simply move all the child's children across to the parent (see Figure~\ref{?}). If, on the other hand, we are retaining the child, we move all the parent's children \emph{except the child} across to the child (see Figure~\ref{?}). Moving a node involves modifying its parent pointer to point to the surviving node and adding a graph edge that joins it to the surviving node (the graph edge joining it to the node being removed will be automatically removed when that node is).

It is important to check whether the root node is the one being removed -- if so, we need to make the surviving node into the new root node. Finally, we remove the node as planned and return the index of the surviving node.
