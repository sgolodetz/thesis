\chapter{Research Methodology}
\label{chap:methodology}

%---
\section{Chapter Overview}

In Chapter~\ref{chap:background}, the major techniques currently in use for medical image segmentation were surveyed, with the intent of placing the specific methods I used for my work within the context of the field as a whole. This chapter builds on that foundation by discussing both my goals and the methods I then chose to try to achieve them, with particular emphasis on their appropriateness in each case. The aim is to address the question of why my research was undertaken in the manner it was, before focusing on how it was undertaken in Chapters~\ref{chap:ipfs} through \ref{chap:applications}.

%---
\section{Goals}

The overarching goal of my doctorate was to conduct research into ways of segmenting abdominal CT scans and identifying salient features therein. There are a number of important use cases which make research into this area worthwhile, but the two I have been particularly interested in are those of volume visualization and volume estimation (see Chapter~\ref{chap:applications}).

Visualization is the process of rendering information in a manner intended to aid human understanding. In the context of medical imaging, the term volume visualization (also known as volume rendering) generally refers to the process of taking a three-dimensional volume of scan data (for example, a series of CT slices) and rendering it onto a two-dimensional screen. This is potentially useful to clinicians because it allows them to view the state of the imaged part of the body as a whole, rather than having to mentally visualize the situation based on what they can see on the individual 2D images. For similar reasons, it is also potentially of benefit to anyone with a less finely-honed knowledge of anatomy (e.g.~non-medics, or indeed early-stage medical students). In order to work, volume visualization techniques need some idea of where different features are in the images: for example, the multiple material marching cubes algorithm \cite{wu03} for volume rendering takes as input a volume where each voxel is assigned a label corresponding to a feature of interest (e.g.~a kidney). The construction of such a labelled volume from an initial data-set is the kind of segmentation/feature identification problem discussed in this dissertation.

The second use case, volume estimation, is the process of estimating the volumes of particular features of interest (such as organs, or tumours) from medical images. There are various potential uses to which clinicians can put such information. For certain types of tumour, it is hypothesized \cite{?} that changes in the volume of a tumour are a good indicator as to the efficacy of a patient's current treatment regime, and can thus help inform treatment decisions. (It should be noted, however, that this is by no means always the case -- indeed, in the case of liver tumours at a minimum the picture has been shown to be much more complicated \cite{?}.) Changes in organ volumes following partial resections are also of interest to clinicians: as part of my work on volume estimation, I provided data for a clinical study investigating the extent to which a reduction in kidney volume following a partial nephrectomy (i.e.~an operation to remove part of a kidney) led to a corresponding reduction in renal function \cite{pbgmvc09}. Regardless of the uses to which the volume information is ultimately put, however, volume estimation in general once again relies entirely on knowing where whichever feature is of interest lies within the scans: the real problem is not how to sum, for example, the number of voxels marked as kidney, but how to identify the voxels as kidney in the first place.

Segmentation and feature identification, then, are key problems that must be tackled when intending to apply certain other medical imaging algorithms with more direct real-world uses. The ideal response to the challenge they pose would evidently be to devise unsupervised (or automated) algorithms which could segment images and identify their salient features with 100\% accuracy, but this is virtually impossible in practice -- indeed, even humans can find it hard to identify key features in images when they lack specialist knowledge about the contents. Segmentation and feature identification approaches thus tend to be quite customised, and to involve a certain amount of supervision by the user to ensure that they are doing the right thing.

These two considerations of automation and supervision have proved key to the design of my research. On the one hand, in the context of segmenting an image volume consisting of a large number of slices, it is clearly undesirable to require the end user (e.g.~a radiologist with a busy schedule) to interact substantively with every slice. Segmenting an entire image series by hand can easily take several hours: some degree of automation is therefore extremely desirable. On the other hand, because automated segmentation algorithms will never be 100\% accurate, and because clinicians naturally need some degree of certainty about the results when they will affect real people, it is crucial that they retain the ability to view and edit the results of any automated algorithms used. A system whose output cannot be edited to correct mistakes is of little to no use in a clinical setting.

The goal I therefore adopted for my segmentation and feature identification work was a compromise: to devise an approach that was as automated as possible, to reduce the interactivity burden on the user, whilst simultaneously allowing (but not requiring) as much interaction as possible, to allow the user to correct any errors in the results. This principle has fundamentally affected the methods I have chosen, as described in the next section.

%---
\section{Methods}

TODO

\begin{figure}[p]
\begin{center}
\footnotesize
\begin{tabular}{p{3cm}||p{6.5cm}|p{6.5cm}}
	& \parbox{6cm}{\centering \textbf{Some Advantages}} & \parbox{6cm}{\centering \textbf{Some Disadvantages}} \\
	\hline\hline
	%
	\textbf{Thresholding}
	& \singleitem{+}{Conceptually simple} & \singleitem{--}{Non-contiguous results} \\
	& \singleitem{+}{It is sometimes possible to automatically generate good thresholds} & \singleitem{--}{Appropriate thresholds may not exist when grey value distributions of different features overlap} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Unclear how to facilitate editing}
	\\
	\hline
	\nohyphens{\textbf{Region Growing}}
	& \singleitem{+}{Conceptually simple} & \singleitem{--}{Requires seed point generation} \\
	& \singleitem{+}{Contiguous results} & \singleitem{--}{Results may still have holes} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Unclear how to facilitate editing when region growing over pixels}
	\\
	\hline
	\textbf{Watershed from Markers}
	& \singleitem{+}{Regions contiguous, no holes} & \singleitem{--}{Requires marker specification (tricky to automate in general)} \\
	& \singleitem{+}{Segments the entire image, rather than just an individual object (useful if trying to find lots of different features)} & \singleitem{--}{Unclear how to facilitate editing} \\
	& \singleitem{+}{Divides the image into a specified number of regions} \\
	& \singleitem{+}{Works in either 2D or 3D}
	\\
	\hline
	\textbf{Watershed and Waterfall}
	& \singleitem{+}{Effectively automatic (although pre-processing and windowing require parameters)} & \singleitem{--}{Good initial segmentation reliant on being able to establish a correspondence between features of interest and catchment basins} \\
	& \singleitem{+}{Regions contiguous, no holes} \\
	& \singleitem{+}{Segments the entire image, rather than just an individual object (useful if trying to find lots of different features)} \\
	& \singleitem{+}{Hierarchical, so can be used to construct a tree/forest, which can be edited later} \\
	& \singleitem{+}{Works in either 2D or 3D}
	\\
	\hline
	\textbf{Snakes}
	& \singleitem{+}{Result bounds contiguous region} & \singleitem{--}{Requires initial contour} \\
	& \singleitem{+}{Conceptually simpler than level sets} & \singleitem{--}{Manual tweaking often necessary} \\
	& \singleitem{+}{Editing possible by dragging contour} & \singleitem{--}{Doesn't translate easily into 3D}
	\\
	\hline
	\textbf{Level Sets}
	& \singleitem{+}{Can easily represent features which are split into multiple pieces} & \singleitem{--}{Requires initial contour and parameters} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Manual tweaking often necessary}
	\\
	\hline
	\textbf{Atlas-Based}
	& & \singleitem{--}{Atlas construction requires large amounts of data} \\
	& & \singleitem{--}{Doesn't handle unusual cases well}
	\\
	\hline
	\textbf{Neural Nets}
	& & \singleitem{--}{Workings tend to be opaque} \\
	& & \singleitem{--}{Requires large amounts of training data} \\
	& & \singleitem{--}{Doesn't handle unusual cases well}
	\\
	\hline
	\textbf{Clustering}
	& & \singleitem{--}{More appropriate when the number of clusters is known in advance (e.g.~for brain images)}
	\\
	\hline
	\textbf{Normalized Cuts}
	& \singleitem{+}{Good for low-contrast images} & \singleitem{--}{Biased towards even partitions}
\end{tabular}
\end{center}
\caption{A comparison of the segmentation methods available, with reference to my goals}
\label{fig:methodology-methods-comparison}
\end{figure}

%---
\section{Chapter Summary}

This chapter has explained the goals of my doctorate and the methods I chose to try to achieve them, and discussed in detail why both were appropriate. In Chapter~\ref{chap:ipfs}, I will describe and define partition forests, the key data structure I used to represent images for feature identification purposes, and present novel algorithms for working with them.
