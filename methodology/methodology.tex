\chapter{Research Methodology}
\label{chap:methodology}

%---
\section{Chapter Overview}

In Chapter~\ref{chap:background}, the major techniques currently in use for medical image segmentation were surveyed, with the intent of placing the specific methods I used for my work within the context of the field as a whole. This chapter builds on that foundation by discussing both my goals and the methods I then chose to try to achieve them, with particular emphasis on their appropriateness in each case. The aim is to address the question of why my research was undertaken in the manner it was, before focusing on how it was undertaken in Chapters~\ref{chap:ipfs} through \ref{chap:featureid}. This chapter concludes with a discussion of the real-world context of the work, since medical imaging research is not an activity that can be undertaken without substantial collaboration with those in the medical profession. This forms part of the essential background for my critical assessment in Chapter~\ref{chap:assessment}.

%---
\section{Goals}

\index{research!goals|(}

The overarching goal of my doctorate has been to conduct research into ways of segmenting abdominal CT scans and identifying salient features therein. There are a number of important use cases which make research into this area worthwhile, but the two I have been particularly interested in are those of volume visualisation and volume estimation (see Appendix~\ref{chap:appendixapps}).

\textbf{Visualisation} is the process of rendering information in a manner intended to aid human understanding. In the context of medical imaging, the term volume visualisation (also known as volume rendering) generally refers to the process of taking a three-dimensional volume of scan data (for example, a series of CT slices) and rendering it onto a two-dimensional screen. This is potentially useful to clinicians because it allows them to view the state of the imaged part of the body as a whole, rather than having to mentally visualise the situation based on what they can see on the individual 2D images. For similar reasons, it is also potentially of benefit to anyone with a less finely-honed knowledge of anatomy (e.g.~non-medics, or indeed early-stage medical students). In order to work, volume visualisation techniques need some idea of where different features are in the images: for example, the multiple material marching cubes algorithm \cite{wu03} for volume rendering takes as input a volume where each voxel is assigned a label corresponding to a feature of interest (e.g.~a kidney). The construction of such a labelled volume from an initial data-set is the kind of segmentation/feature identification problem discussed in this thesis.

\textbf{Volume estimation} is the process of estimating the volumes of particular features of interest (such as organs, or tumours) from medical images. There are various potential uses to which clinicians can put such information. Changes in the size of a tumour as a result of therapy are a common criterion used to assess the efficacy of a patient's current treatment regime \cite{recist09}, and can be used to help inform treatment decisions. (It should be noted, however, that for heterogeneous tumours -- those whose cells are not all genetically identical -- volume shrinkage per se is believed to be a less useful indicator of therapeutic response, because it is possible for the less aggressive parts of a tumour to shrink in size whilst leaving the more aggressive parts unaffected. This is outside the scope of this thesis, but the interested reader is encouraged to consult \cite{kelly07}, in which Kelly et al.\ present a way of modelling such heterogeneous tumours using sets of expanding spheres.) Changes in organ volumes following partial resections are also of interest to clinicians: as part of my work on volume estimation, I provided data for a clinical study investigating the extent to which a reduction in kidney volume following a partial nephrectomy (i.e.~an operation to remove part of a kidney) led to a corresponding reduction in renal function \cite{pbgmvc09}. Regardless of the uses to which the volume information is ultimately put, however, volume estimation in general once again relies entirely on knowing where whichever feature is of interest lies within the scans: the real problem is not how to sum, for example, the number of voxels marked as kidney, but how to identify the voxels as kidney in the first place.

Segmentation and feature identification, then, are key problems that must be tackled when intending to apply certain other medical imaging algorithms with more direct real-world uses. The ideal response to the challenge they pose would evidently be to devise unsupervised (or automated) algorithms which could segment images and identify their salient features with 100\% accuracy, but this is virtually impossible in practice -- indeed, even humans can find it hard to identify key features in images when they lack specialist knowledge about the contents. Segmentation and feature identification approaches thus tend to be quite customised, and to involve a certain amount of supervision by the user to ensure that they are doing the right thing.

These two considerations of automation and supervision have proved key to the design of my research. On the one hand, in the context of segmenting an image volume consisting of a large number of slices, it is clearly undesirable to require the end user (e.g.~a radiologist with a busy schedule) to interact substantively with every slice. Segmenting an entire image series by hand can easily take several hours: some degree of automation is therefore extremely desirable. On the other hand, because automated segmentation algorithms will never be 100\% accurate, and because clinicians naturally need some degree of certainty about the results when they will affect real people, it is crucial that they retain the ability to view and edit the results of any automated algorithms used. A system whose output cannot be edited to correct mistakes is of little to no use in a clinical setting.

The goal I therefore adopted for my segmentation and feature identification work was a compromise: to devise an approach that was as automated as possible, to reduce the interactivity burden on the user, whilst simultaneously allowing (but not requiring) as much interaction as possible, to allow the user to correct any errors in the results. This principle fundamentally affected the methods I chose, as described in the next section.

\index{research!goals|)}

%---
\section{Methods}

\index{research!methods|(}

%---
\begin{table}[p]
\begin{center}
\footnotesize
\begin{tabular}{p{3cm}||p{6cm}|p{6cm}}
	& \parbox{6cm}{\centering \textbf{Some Advantages}} & \parbox{6cm}{\centering \textbf{Some Disadvantages}} \\
	\hline\hline
	%
	\textbf{Thresholding}
	& \singleitem{+}{Conceptually simple} & \singleitem{--}{Non-contiguous results} \\
	& \singleitem{+}{It is sometimes possible to generate good thresholds automatically} & \singleitem{--}{Appropriate thresholds may not exist when the grey value distributions of different features overlap} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Unclear how to facilitate editing}
	\\
	\hline
	\nohyphens{\textbf{Region Growing}}
	& \singleitem{+}{Conceptually simple} & \singleitem{--}{Requires seed point generation} \\
	& \singleitem{+}{Contiguous results} & \singleitem{--}{Results may still have holes} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Unclear how to facilitate editing when region growing over pixels}
	\\
	\hline
	\textbf{\mbox{Watershed from} Markers}
	& \singleitem{+}{Regions contiguous, no holes} & \singleitem{--}{Requires marker specification (tricky to automate in general)} \\
	& \singleitem{+}{Segments the entire image, rather than just an individual object (useful if trying to find lots of different features)} & \singleitem{--}{Unclear how to facilitate editing} \\
	& \singleitem{+}{Divides the image into a specified number of regions} \\
	& \singleitem{+}{Works in either 2D or 3D}
	\\
	\hline
	\textbf{\mbox{Watershed and} Waterfall}
	& \singleitem{+}{Effectively automatic (aside from windowing and pre-processing, which require parameters)} & \singleitem{--}{Good initial segmentation reliant on being able to establish a correspondence between features of interest and catchment basins} \\
	& \singleitem{+}{Regions contiguous, no holes} \\
	& \singleitem{+}{Hierarchical, so can be used to construct a tree/forest, which can be edited later} \\
	& \singleitem{+}{Handles unusual cases well} \\
	& \singleitem{+}{Works in either 2D or 3D}
	\\
	\hline
	\textbf{Snakes}
	& \singleitem{+}{Result bounds contiguous region} & \singleitem{--}{Requires initial contour} \\
	& \singleitem{+}{Conceptually simpler than level sets} & \singleitem{--}{Manual tweaking often necessary} \\
	& \singleitem{+}{Editing possible by dragging contour} & \singleitem{--}{Doesn't translate easily into 3D}
	\\
	\hline
	\textbf{Level Sets}
	& \singleitem{+}{Can easily represent features which are split into multiple pieces} & \singleitem{--}{Requires an initial contour and parameters} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Manual tweaking often necessary}
	\\
	\hline
	\textbf{Atlas-Based}
	& \singleitem{+}{Aids decision-making when the image is unclear} & \singleitem{--}{Construction requires large amounts of data} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Doesn't handle unusual cases well}
	\\
	\hline
	\textbf{Neural Nets}
	& \singleitem{+}{Aids decision-making when the image is unclear} & \singleitem{--}{Requires large amounts of training data} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Workings tend to be opaque} \\
	& & \singleitem{--}{Doesn't handle unusual cases well}
	\\
	\hline
	\textbf{Clustering}
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{More appropriate when the number of clusters is known in advance (e.g.~for brain images)}
	\\
	\hline
	\textbf{Normalized Cuts}
	& \singleitem{+}{Good for low-contrast images} & \singleitem{--}{Biased towards even partitions} \\
	& \singleitem{+}{Works in either 2D or 3D}
\end{tabular}
\end{center}
\caption{A comparison of available segmentation methods}
\label{fig:methodology-methods-comparison}
\end{table}
%---

As discussed in detail in Chapter~\ref{chap:background}, there are a wide variety of image segmentation and feature identification methods currently used. Having compared (see Table~\ref{fig:methodology-methods-comparison}) the relative advantages and disadvantages of a number of methods, however, I decided that a segmentation approach based on the watershed and waterfall transforms was the most appropriate choice for my research, as it has a number of useful properties:
%
\begin{enumerate}

\item It can be made to produce a reasonable (if not perfect) initial segmentation of an image virtually automatically, without any requirement to specify e.g.~seed points (region growing), markers (watershed from markers), initial contours (snakes and level sets) or other parameters.

\item It produces contiguous regions. Region contiguity is desirable because the objects of interest in an image tend to be contiguous (or, at worst, split into a few pieces). Thresholding generally produces regions which are neither contiguous nor hole-free, as do clustering techniques.

\item It provides a mechanism for the user to edit the initial segmentation, as its output can be used to construct a partition hierarchy that can be edited using the algorithms I will present in Chapter~\ref{chap:ipfs}. By contrast, it is unclear how to facilitate editing for a number of other techniques such as thresholding, watershed from markers, clustering, normalized cuts or region growing over pixels (although, as we will see later, editing the results of region growing over nodes in an adjacency graph is more possible).

\item It handles unusual cases well because -- unlike, for example, atlas-based and neural network methods -- it does not rely on specific features being in their expected places in an image. Moreover, it does not have the requirements of those methods for large amounts of training data to be available.

\item It can be easily extended to work with 3D images (unlike snakes).

\end{enumerate}
%
The watershed and waterfall transforms, and the way in which I used them to construct a partition hierarchy, are described in Chapter~\ref{chap:segmentation}.

To actually identify features within the hierarchy, I used a number of customised approaches, all of which are discussed in more detail in Chapter~\ref{chap:featureid}. Most of these approaches are based on one of two fundamental techniques: \emph{branch node filtering} (searching for branch nodes in the hierarchy that satisfy specific criteria) or \emph{stratified region growing} (finding seed regions throughout the hierarchy and performing region growing on a per-layer basis before combining the results) -- see \S\ref{sec:featureid-techniques}. Branch node filtering was used when a feature (e.g.~the spinal canal) was seen to be relatively distinctive in the images, leading it to correspond to a very small number of regions in the hierarchy; otherwise, stratified region growing was used instead.

Despite being based on region growing, with its various disadvantages listed in Table~\ref{fig:methodology-methods-comparison}, stratified region growing has some merit for the type of region-level feature identification used here, because the disadvantages are somewhat less applicable in this case. Firstly, seed regions in the hierarchy are relatively easy to generate, since it is possible to associate a large number of properties with each region in the hierarchy on which such a decision can be based. Secondly, the features identified (e.g.~the spine and kidneys) are relatively homogeneous in the images, so the results produced tend not to contain an excessive number of holes. Finally, stratified region growing produces as its result the selection of a manageable number of nodes in the partition hierarchy, which can be easily edited using the hierarchy algorithms presented in Chapter~\ref{chap:ipfs}.

\index{research!methods|)}

%---
\section{Real-World Context}

\index{research!context|(}

Medical image research cannot (and, in any case, should not) be undertaken without active collaboration with those in the medical profession. In the case of my doctoral work, we were fortunate enough to establish such links with four consultants in the Churchill Hospital, Oxford, through the invaluable help of Professor Sir Mike Brady (at the time, running a medical imaging group in Oxford University's Department of Engineering Science).

However, the time it takes to set up such a collaboration should not be underestimated (especially because medics have commitments to patients that limit the amount of time they are able to spend on research), and this had important implications for the way my research evolved. Not least of these was that the initial research plan and early work had to be designed in something of a vacuum, with the aim of convincing the doctors that the project was worthwhile. Whilst this presented certain difficulties (my lack of the relevant medical knowledge made it hard to devise a coherent plan, and early on I had no access to any CT images on which to try out my ideas), it also made the process very interesting, because it gave me valuable insights into how research links are established -- in many ways, the process involves as much marketing as technical development, something of which I had previously had little experience.

Since establishing medical links, the project has proceeded well from the perspective of my doctoral work. However, it will become important in future to establish further links with both potential end-users and the external companies that currently supply them if any of the techniques described in this thesis are ultimately to be put to use in a clinical environment.

\index{research!context|)}

\newpage

%---
\section{Chapter Summary}

This chapter has explained the goals of my doctorate and the methods I chose to try to achieve them, and discussed in detail why both were appropriate. It has also looked at the real-world context of my doctorate, and how that affected the way my research proceeded. The following three chapters now turn to look at the research itself. In Chapter~\ref{chap:ipfs}, therefore, I will describe partition forests, the key data structure I used to represent images for feature identification purposes, and present novel algorithms for working with them.
