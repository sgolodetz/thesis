\chapter{Research Methodology}
\label{chap:methodology}

%---
\section{Chapter Overview}

In Chapter~\ref{chap:background}, the major techniques currently in use for medical image segmentation were surveyed, with the intent of placing the specific methods I used for my work within the context of the field as a whole. This chapter builds on that foundation by discussing both my goals and the methods I then chose to try to achieve them, with particular emphasis on their appropriateness in each case. The aim is to address the question of why my research was undertaken in the manner it was, before focusing on how it was undertaken in Chapters~\ref{chap:ipfs} through \ref{chap:applications}.

%---
\section{Goals}

The overarching goal of my doctorate was to conduct research into ways of segmenting abdominal CT scans and identifying salient features therein. There are a number of important use cases which make research into this area worthwhile, but the two I have been particularly interested in are those of volume visualization and volume estimation (see Chapter~\ref{chap:applications}).

Visualization is the process of rendering information in a manner intended to aid human understanding. In the context of medical imaging, the term volume visualization (also known as volume rendering) generally refers to the process of taking a three-dimensional volume of scan data (for example, a series of CT slices) and rendering it onto a two-dimensional screen. This is potentially useful to clinicians because it allows them to view the state of the imaged part of the body as a whole, rather than having to mentally visualize the situation based on what they can see on the individual 2D images. For similar reasons, it is also potentially of benefit to anyone with a less finely-honed knowledge of anatomy (e.g.~non-medics, or indeed early-stage medical students). In order to work, volume visualization techniques need some idea of where different features are in the images: for example, the multiple material marching cubes algorithm \cite{wu03} for volume rendering takes as input a volume where each voxel is assigned a label corresponding to a feature of interest (e.g.~a kidney). The construction of such a labelled volume from an initial data-set is the kind of segmentation/feature identification problem discussed in this dissertation.

The second use case, volume estimation, is the process of estimating the volumes of particular features of interest (such as organs, or tumours) from medical images. There are various potential uses to which clinicians can put such information. It is thought \cite{?} that in some cases changes in the volume of a tumour may be a good indicator as to the efficacy of a patient's current treatment regime, and can thus help inform treatment decisions. (It should be noted, however, that this is by no means always the case -- indeed, in the case of liver tumours at a minimum the picture is thought to be more complicated \cite{kelly07}.) Changes in organ volumes following partial resections are also of interest to clinicians: as part of my work on volume estimation, I provided data for a clinical study investigating the extent to which a reduction in kidney volume following a partial nephrectomy (i.e.~an operation to remove part of a kidney) led to a corresponding reduction in renal function \cite{pbgmvc09}. Regardless of the uses to which the volume information is ultimately put, however, volume estimation in general once again relies entirely on knowing where whichever feature is of interest lies within the scans: the real problem is not how to sum, for example, the number of voxels marked as kidney, but how to identify the voxels as kidney in the first place.

Segmentation and feature identification, then, are key problems that must be tackled when intending to apply certain other medical imaging algorithms with more direct real-world uses. The ideal response to the challenge they pose would evidently be to devise unsupervised (or automated) algorithms which could segment images and identify their salient features with 100\% accuracy, but this is virtually impossible in practice -- indeed, even humans can find it hard to identify key features in images when they lack specialist knowledge about the contents. Segmentation and feature identification approaches thus tend to be quite customised, and to involve a certain amount of supervision by the user to ensure that they are doing the right thing.

These two considerations of automation and supervision have proved key to the design of my research. On the one hand, in the context of segmenting an image volume consisting of a large number of slices, it is clearly undesirable to require the end user (e.g.~a radiologist with a busy schedule) to interact substantively with every slice. Segmenting an entire image series by hand can easily take several hours: some degree of automation is therefore extremely desirable. On the other hand, because automated segmentation algorithms will never be 100\% accurate, and because clinicians naturally need some degree of certainty about the results when they will affect real people, it is crucial that they retain the ability to view and edit the results of any automated algorithms used. A system whose output cannot be edited to correct mistakes is of little to no use in a clinical setting.

The goal I therefore adopted for my segmentation and feature identification work was a compromise: to devise an approach that was as automated as possible, to reduce the interactivity burden on the user, whilst simultaneously allowing (but not requiring) as much interaction as possible, to allow the user to correct any errors in the results. This principle fundamentally affected the methods I chose, as described in the next section.

%---
\section{Methods}

%---
\begin{figure}[p]
\begin{center}
\footnotesize
\begin{tabular}{p{3cm}||p{6.5cm}|p{6.5cm}}
	& \parbox{6cm}{\centering \textbf{Some Advantages}} & \parbox{6cm}{\centering \textbf{Some Disadvantages}} \\
	\hline\hline
	%
	\textbf{Thresholding}
	& \singleitem{+}{Conceptually simple} & \singleitem{--}{Non-contiguous results} \\
	& \singleitem{+}{It is sometimes possible to automatically generate good thresholds} & \singleitem{--}{Appropriate thresholds may not exist when grey value distributions of different features overlap} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Unclear how to facilitate editing}
	\\
	\hline
	\nohyphens{\textbf{Region Growing}}
	& \singleitem{+}{Conceptually simple} & \singleitem{--}{Requires seed point generation} \\
	& \singleitem{+}{Contiguous results} & \singleitem{--}{Results may still have holes} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Unclear how to facilitate editing when region growing over pixels}
	\\
	\hline
	\textbf{Watershed from Markers}
	& \singleitem{+}{Regions contiguous, no holes} & \singleitem{--}{Requires marker specification (tricky to automate in general)} \\
	& \singleitem{+}{Segments the entire image, rather than just an individual object (useful if trying to find lots of different features)} & \singleitem{--}{Unclear how to facilitate editing} \\
	& \singleitem{+}{Divides the image into a specified number of regions} \\
	& \singleitem{+}{Works in either 2D or 3D}
	\\
	\hline
	\textbf{Watershed and Waterfall}
	& \singleitem{+}{Effectively automatic (although pre-processing and windowing require parameters)} & \singleitem{--}{Good initial segmentation reliant on being able to establish a correspondence between features of interest and catchment basins} \\
	& \singleitem{+}{Regions contiguous, no holes} \\
	& \singleitem{+}{Hierarchical, so can be used to construct a tree/forest, which can be edited later} \\
	& \singleitem{+}{Handles unusual cases well} \\
	& \singleitem{+}{Works in either 2D or 3D}
	\\
	\hline
	\textbf{Snakes}
	& \singleitem{+}{Result bounds contiguous region} & \singleitem{--}{Requires initial contour} \\
	& \singleitem{+}{Conceptually simpler than level sets} & \singleitem{--}{Manual tweaking often necessary} \\
	& \singleitem{+}{Editing possible by dragging contour} & \singleitem{--}{Doesn't translate easily into 3D}
	\\
	\hline
	\textbf{Level Sets}
	& \singleitem{+}{Can easily represent features which are split into multiple pieces} & \singleitem{--}{Requires initial contour and parameters} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Manual tweaking often necessary}
	\\
	\hline
	\textbf{Atlas-Based}
	& \singleitem{+}{Aids decision-making when the image is unclear} & \singleitem{--}{Construction requires large amounts of data} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Doesn't handle unusual cases well}
	\\
	\hline
	\textbf{Neural Nets}
	& \singleitem{+}{Aids decision-making when the image is unclear} & \singleitem{--}{Workings tend to be opaque} \\
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{Requires large amounts of training data} \\
	& & \singleitem{--}{Doesn't handle unusual cases well}
	\\
	\hline
	\textbf{Clustering}
	& \singleitem{+}{Works in either 2D or 3D} & \singleitem{--}{More appropriate when the number of clusters is known in advance (e.g.~for brain images)}
	\\
	\hline
	\textbf{Normalized Cuts}
	& \singleitem{+}{Good for low-contrast images} & \singleitem{--}{Biased towards even partitions} \\
	& \singleitem{+}{Works in either 2D or 3D}
\end{tabular}
\end{center}
\caption{A comparison of available segmentation methods}
\label{fig:methodology-methods-comparison}
\end{figure}
%---

As discussed in detail in Chapter~\ref{chap:background}, there are a wide variety of image segmentation and feature identification methods currently used. Having compared (see Figure~\ref{fig:methodology-methods-comparison}) the relative advantages and disadvantages of a number of methods, however, I decided that a segmentation approach based on the watershed and waterfall transforms was the most appropriate choice for my research, as it has a number of useful properties:
%
\begin{enumerate}

\item It can be made to produce a reasonable (if not perfect) initial segmentation of an image virtually automatically, without any requirement to specify e.g.~seed points (region growing), markers (watershed from markers), initial contours (snakes and level sets) or other parameters.

\item It produces contiguous regions. Region contiguity is desirable because the objects of interest in an image tend to be contiguous (or, at worst, split into a few pieces). Thresholding generally produces regions which are neither contiguous nor hole-free, as do clustering techniques.

\item It provides a mechanism for the user to edit the initial segmentation, as its output can be used to construct a partition hierarchy that can be edited using the algorithms I will present in Chapter~\ref{chap:ipfs}. By contrast, it is unclear how to facilitate editing for a number of other techniques such as thresholding, watershed from markers, clustering, normalized cuts or region growing over pixels (although, as we will see later, editing the results of region growing over nodes in an adjacency graph is more possible).

\item It handles unusual cases well because -- unlike, for example, atlas-based and neural network methods -- it does not rely on specific features being in their expected places in an image. Moreover, it does not have the requirements of those methods for large amounts of training data to be available.

\item It can be easily extended to work with 3D images (unlike snakes).

\end{enumerate}
%
The watershed and waterfall transforms, and the way in which I used them to construct a partition hierarchy, are described in Chapter~\ref{chap:segmentation}. To actually identify features within the hierarchy, I used two separate approaches, both of which are discussed in more detail in Chapter~\ref{chap:featureid}. For distinctive features such as ribs, I simply applied a Bayesian classifier to each region in the hierarchy. This was appropriate because each rib generally corresponded directly to a very small number (usually $1$ or $2$) of regions in the hierarchy.

For other features, I developed a more sophisticated region growing approach that works on the adjacency graphs of the hierarchy. Region growing was an appropriate technique in this case because the disadvantages listed for it in Figure~\ref{fig:methodology-methods-comparison} were less applicable here. Firstly, seed regions in the hierarchy were relatively easy to generate, as a result of the large number of properties associated with each region on which such a decision could be based. Secondly, the features being identified (e.g.~the spine and kidneys) were relatively homogeneous in the image, so the results produced tended not to contain an excessive number of holes. Finally, my method produced as its result the selection of a manageable number of nodes in the partition hierarchy, which could be easily edited using the hierarchy algorithms presented in Chapter~\ref{chap:ipfs}.

\newpage

%---
\section{Chapter Summary}

This chapter has explained the goals of my doctorate and the methods I chose to try to achieve them, and discussed in detail why both were appropriate. In Chapter~\ref{chap:ipfs}, I will describe and define partition forests, the key data structure I used to represent images for feature identification purposes, and present novel algorithms for working with them.
