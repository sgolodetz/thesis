\chapter{Introduction}
\label{chap:introduction}

In the most general sense, the problem of segmentation is the challenge of how to partition an object into pieces in such a way as to ensure that those pieces have some meaning in a given domain. The related (and to some extent overlapping) problem of feature identification is how to then ascribe meaning to some or all of those pieces. Whilst a huge variety of techniques have been developed for these problems, there are many domains in which it is difficult to specify, at least in a sufficiently precise manner, what constitutes a meaningful piece and what does not. For that reason, both problems remain major research challenges.

Nevertheless, an ability to solve these problems, even in an imperfect way, is often a crucial precursor to applying other algorithms in various domains, making them worthy targets for research efforts. For example, in the medical imaging domain, it is helpful to be able to translate a volume of data produced by a scanner into a 3D mesh, allowing doctors to visualize the state of a patient's organs in a more direct manner. Whilst there are existing algorithms to convert \emph{labelled} volume data to a 3D mesh (e.g.~\cite{wu03}), these rely on \emph{a priori} knowledge of the location of the organs. That is, they rely on the organs having being labelled in the volume in advance. Producing such a labelling is a segmentation and feature identification problem.

This thesis is about tackling the segmentation and feature identification problems for a particular type of medical image, namely computerised tomography (CT) scans of a patient's abdomen. The first practical CT scanner was developed in 1971 by Sir Godfrey Hounsfield, working at the EMI Central Research Laboratories in Hayes, UK.\footnote{Credit for the CT technique is also due to Allan McLeod Cormack of Tufts University in Massachusetts in the United States, who independently developed the theory underpinning CT in the late 1950s and early 1960s. Both men shared the 1979 Nobel Prize in Physiology or Medicine.} CT scanners work using X-rays and produce images whose pixels are scalar values on a scale of radiodensity known (after Sir Godfrey) as the Hounsfield scale. They are used extensively in modern medical practice \cite{garvey02}, both for diagnosing illness and for evaluating a patient's response to therapy.

%---
\stufigex{height=8cm}{introduction/introduction-labelledabdominalscan.png}{An abdominal CT scan of a patient with a large renal tumour on the left kidney. Some of the key features in the scan are labelled.}{fig:introduction-labelledabdominalscan}{t}
%---

My underlying interest is in renal (kidney) cancers, in the diagnosis of which CT scanners are generally used to produce images of the abdomen (see Figure~\ref{fig:introduction-labelledabdominalscan}). Whilst less prevalent than some other types of cancer -- notably breast, lung, colorectal and prostate -- renal cancers nevertheless kill thousands of people a year in the UK.\footnote{According to Cancer Research UK \cite{cruk-kidneycancermortality}, 3752 people died from a kidney cancer in the UK in 2007, the most recent year for which published statistics are currently available.} An ability to visualize the state of a renal cancer patient's abdominal organs in 3D can provide doctors with an extra tool when making important decisions about how best to treat the patient. In a similar vein, being able to calculate the volume of a renal tumour can help doctors track changes over time that may be relevant when evaluating a patient's response to therapy. For these, and other, applications, finding a way to segment and identify features in abdominal CT scans is a key prerequisite.

%---
\stufigex{height=6cm}{introduction/introduction-campadelli.png}{An example output of the fully-automatic technique to identify abdominal organs described in \cite{campadelli09} (extracted from Figure 7 of that paper), showing the excellent results they obtained when automatically identifying the bones, heart and kidneys.}{fig:introduction-campadelli}{t}
%---

Given the relevance of the abdominal CT segmentation and feature identification problems, it is unsurprising that significant research effort has been devoted to them in recent years. Approaches range from manual, where the user is required to draw round the relevant features in every slice, to semi-automatic, where the user has to do some of the segmentation work but can then leave the rest to the computer (e.g.~\cite{loncaric00}), to fully-automatic, where abdominal features are extracted with no relevant user interaction. Two particularly noteworthy fully-automatic methods are \cite{campadelli09} and \cite{shimizu07}. In \cite{campadelli09}, Campadelli et al.\ described a grey-level based framework that allowed them to automatically extract the bones, heart, kidneys, liver (including its blood vessels) and spleen from CT scans (e.g.~see Figure~\ref{fig:introduction-campadelli}), an approach they tested on images from $100$ patients. Full validation was done for the liver and spleen, by comparing the output to three expert ground truth segmentations, with excellent results being achieved for those organs. In \cite{shimizu07}, Shimizu et al.\ proposed an atlas-guided approach that attempted to automatically extract twelve abdominal features (aorta, gallbladder, heart, inferior vena cava, left kidney, liver, oesophagus, pancreas, portal vein, right kidney, spleen and stomach). Whilst they only tested their approach on images from $10$ patients, they achieved promising results for most of the major organs (see Figure~\ref{fig:introduction-shimizu}). One slight downside is the significant amount of computing power used by their approach (a message passing interface (MPI) implementation running on $16$ 2.8GHz CPUs, each with 4GB of memory), although it seems plausible that this could be reduced.

%---
\stufigex{height=6cm}{introduction/introduction-shimizu.png}{An example output of the fully-automatic technique to identify abdominal organs described in \cite{shimizu07} (extracted from Figure 8 of that paper). Twelve features have been identified: the aorta (pink), gallbladder (light green), heart (yellow), inferior vena cava (red), left kidney (light orange), liver (maroon), oesophagus (purple), pancreas (green), portal vein (light blue), right kidney (orange), spleen (white) and stomach (blue).}{fig:introduction-shimizu}{t}
%---

Despite the evident successes of some current fully-automatic approaches, however, it remains the case that whilst medics may not necessarily want to be forced to interact substantively with a segmentation and feature identification application in its initial stages, they are generally keen to retain the ability to carefully examine and edit its output. For that reason, my own approach described in this thesis has focused not just on the fully-automatic identification of abdominal features (although I have done a significant amount of work in that direction, as will be described in Chapter~\ref{chap:featureid}), but also on a good way of facilitating user editing of automatically-generated segmentation and feature identification results.

My approach is based around the idea of representing images using a hierarchical data structure known as a partition forest (or an \emph{image partition forest}, in this context). Partition forests, described more fully in Chapters~\ref{chap:background} and \ref{chap:ipfs}, are in essence a set of hierarchical partitions of the same object (e.g.~an image). Together with partition \emph{trees}, to which they are closely related, they have appeared extensively in the image analysis literature (see \S\ref{sec:background-partitionhierarchies}). However, it is noticeable that despite their seeing widespread use as an image representation technique, surprisingly little work has been done on how to allow partition forests to be easily edited by the user; one notable exception is \cite{nacken95}, in which Peter Nacken describes a constrained parent switching operation for a partition forest-type data structure (I describe a less constrained version of the same operation in Chapter~\ref{chap:ipfs}). In more recent work, Klava et al.~\cite{klava09} take an interesting approach that allows partitions to be viewed as if sibling nodes in the partition forest had been split or merged, via a scheme of defining a non-horizontal cut across the partition forest structure; however, the results obtained using their split and merge operations are fundamentally limited by the underlying forest structure, which they do not change. One of the contributions made by this thesis (in Chapter~\ref{chap:ipfs}) is to fill this gap by defining a hierarchy of undoable operations that can be used to mutate partition forests and showing how they can be integrated into an easy-to-use graphical user interface (GUI). It will be demonstrated that the core operations at the lowest level of this hierarchy are minimally-sufficient for partition forest editing: that is, a finite sequence of them can be used to mutate any partition forest of an object into any other partition forest of the same object.

In addition to algorithms that mutate partition forests, it is also necessary to allow users to manage selections of subtrees within them (due to the forests' hierarchical nature, selecting a node in a forest is equivalent to selecting all of the node's children). Whilst it is evidently simple to support the user's selection of individual nodes within a partition forest (and this has been done), there does not currently appear to be any subtree-based partition forest selection technique in the literature. Such a technique is thus presented in detail in Chapter~\ref{chap:ipfs}, along with techniques for updating partition forest selections based on changes to the underlying forest (for example, a selection must update itself in response to a selected node in the forest being split).

Aside from the aforementioned algorithms, attention needs to be paid to how partition forests should be constructed for CT images. I have developed two different approaches to do this. The first method, which I call \emph{volume-at-once}, segments the (smoothed) gradient magnitude of the image using the well-known watershed transform \cite{beucher90} to produce an initial partition of the image (which becomes the lowest branch layer of the partition forest), and then runs the waterfall transform \cite{marcotegui05} (effectively a series of further watershed transforms) on the result to produce the remainder of the forest layers. When run on a 3D image, this relatively straightforward approach can be used to produce an image partition forest for the whole image. However, it can also be interesting to segment the 3D image on a slice-by-slice basis (in any of the three axis-aligned slice planes), whilst still producing a single image partition forest for the entire volume. To that end, I developed a second method, which I call the \emph{subvolume} method, that segments subvolumes of the 3D image separately and then combines the results to produce an overall forest for the entire image. The details of both of these methods are described in \S\ref{sec:segmentation-ipfconstruction}.

Many elements of the forest construction process are interesting in their own right. For instance, I initially implemented the waterfall transform using the approach described by Marcotegui and Beucher in \cite{marcotegui05}, but my colleague Chris Nicholls devised a simpler, functional-style tree-based algorithm which achieved almost identical results \cite{nicholls09}. In addition to implementing an imperative version of this new algorithm in C++, I subsequently also developed my own slightly more complicated waterfall algorithm that additionally accounts for non-minimal plateaux in the minimum spanning tree on which the algorithm is run in a consistent manner (unlike either of the existing algorithms). All three algorithms are described in detail and compared side-by-side in \S\ref{subsubsec:segmentation-waterfall-comparison}.

With the forest constructed to represent the 3D image, it is possible to devise algorithms to automatically identify features within it. In particular, this thesis presents novel algorithms to identify the spine, spinal canal, ribs, aorta, liver, kidneys and spleen in Chapter~\ref{chap:featureid}. The results of all of these algorithms are validated in Chapter~\ref{chap:validation} against ground truth segmentations that have been manually delineated and confirmed as accurate by a radiologist. Whilst some of the identifiers need further refinement to increase their robustness, the overall approach shows promise.

%---
\stufigex{width=.9\linewidth}{introduction/introduction-centipede.png}{Automatically identifying the ribs and spine in \emph{centipede} and visualizing the feature labelling as a wireframe 3D mesh -- the visible features are the aorta (red), liver (purple), right kidney (yellow) and spine (white).}{fig:introduction-centipede}{t}
%---

I have implemented all of the described techniques and algorithms in C++. Specifically, two separate systems were developed to do segmentation, feature identification and 3D visualization. The trial system, \emph{centipede}, ran only on Microsoft Windows, and segmented each slice in a CT (or MRI) series into its own separate image partition forest. The user could mark features manually, or identify features such as the ribs and spine automatically in 2D CT images (see Figure~\ref{fig:introduction-centipede}). This work was published in \cite{gvccimi08} and \cite{gvcispa09}, with the former paper receiving the Professor Yasuhiko Dote award for the Best Workshop Paper at the Fifth International Conference on Soft Computing as Transdisciplinary Science and Technology (CSTST '08). It was also possible to visualize the results as a wireframe 3D mesh (generated using the multiple material marching cubes algorithm \cite{wu03}).

The final system, \emph{millipede}, is built using a cross-platform build framework called CMake, and runs on Microsoft Windows, Linux and Mac OS X (see Figure~\ref{fig:introduction-millipede-seg}). It allows the user to segment slices from a CT (or MRI) series either as a 3D volume, or as individual axial, coronal or sagittal slices, in all cases producing a single image partition forest for the entire image volume used. Among many other improvements, it supports far better automatic feature identification, this time in 3D, and has built-in tools for validation. It can also visualize the feature identification results as a Phong-lit 3D mesh (see Figure~\ref{fig:introduction-millipede-vis}).

%---
\section*{Contributions}

The original contributions made by this thesis, then, are as follows:

\begin{enumerate}
\item A hierarchy of undoable operations to mutate partition forests, and their integration into a graphical user interface (\S\ref{sec:ipfs-mutatingalgorithms}).
\item A subtree-based, self-updating partition forest selection data structure (\S\ref{sec:ipfs-selections}).
\item A new, implementation-invariant algorithm for the waterfall transform on minimum spanning trees (\S\ref{subsubsec:segmentation-waterfall-myalgorithm}).
\item Two techniques to construct image partition forests for 3D images, making use of the existing watershed and waterfall transforms (\S\ref{sec:segmentation-ipfconstruction}).
\item Novel feature identification techniques for 2D and 3D abdominal CT scans (Chapter~\ref{chap:featureid}).
\item The implementation of the \emph{centipede} and \emph{millipede} segmentation, feature identification and 3D visualization systems in C++.
\end{enumerate}

%---
\begin{stusubfig}{p}
	\subfigure[\emph{millipede} running on Microsoft Windows]
	{\includegraphics[height=.25\textheight]{introduction/introduction-millipede-seg-windows.png}}%
	%
	\\ \vspace{5mm}
	%
	\subfigure[\emph{millipede} running on Linux (Ubuntu)]
	{\includegraphics[height=.25\textheight]{introduction/introduction-millipede-seg-linux.png}}%
	%
	\\ \vspace{5mm}
	%
	\subfigure[\emph{millipede} running on Mac OS X (Snow Leopard)]
	{\includegraphics[height=.25\textheight]{introduction/introduction-millipede-seg-macosx.png}}%
\caption{The final segmentation system I developed, known as \emph{millipede}, is cross-platform.}
\label{fig:introduction-millipede-seg}
\end{stusubfig}
%---

%---
\stufigex{height=6cm}{introduction/introduction-millipede-vis.png}{Visualizing the results of the automatic feature identification techniques in \emph{millipede} as a Phong-lit 3D mesh. Seven features are visible: the aorta (red), right kidney (yellow), liver (purple), ribs (pale green), spine (pale blue), spinal canal (slightly darker blue) and spleen (green).}{fig:introduction-millipede-vis}{t}
%---

%---
\section*{Thesis Organisation}

The remainder of this thesis is organised as follows.

\textbf{Chapter~\ref{chap:background}} surveys the field of image segmentation, and discusses some of the varied uses of partition hierarchies throughout computer science, with the intention of both placing my own techniques in context and providing the foundations for later discussion.

\textbf{Chapter~\ref{chap:methodology}} describes my research methodology in more detail, focusing in particular on the question of the appropriateness of my goals and the methods I chose to achieve them.

\textbf{Chapter~\ref{chap:ipfs}} describes partition forests, the hierarchical data structure I used to represent segmented images, and introduces novel algorithms I developed for editing them and selecting nodes in multiple layers within them.

\textbf{Chapter~\ref{chap:segmentation}} shows how partition forests can be constructed from images by harnessing existing segmentation approaches such as the watershed and waterfall transforms. It looks at three different ways in which the waterfall transform can be implemented: an algorithm due to Marcotegui and Beucher \cite{marcotegui05}, a new tree-based algorithm due to my colleague Chris Nicholls \cite{nicholls09}, and my own novel tree-based approach that handles minimal plateaux in a more explicit manner. It further describes two novel partition forest construction methods that allow a single partition forest to be constructed for an entire image volume, regardless of whether the volume is segmented as a whole or individual image slices are segmented separately.

\textbf{Chapter~\ref{chap:featureid}} discusses my work on automated feature identification in both 2D and 3D. It describes some techniques that are useful for partition forest-based feature identification -- including the novel multi-layer region growing technique I presented in \cite{gvcispa09} -- before presenting my 2D methods for identifying the ribs \cite{gvccimi08} and spine \cite{gvcispa09}, and my 3D methods for identifying the spine, spinal column, ribs, aorta, liver and kidneys \cite{gvcoucl10}.

\textbf{Chapter~\ref{chap:validation}} shows how I validated my approach, and provides quantitative results.

\textbf{Chapter~\ref{chap:assessment}} critically assesses the contributions I claimed above.

\textbf{Chapter~\ref{chap:conclusions}} discusses potential avenues for further work, and concludes the thesis.

\textbf{Appendix~\ref{chap:appendixds}} contains my implementations of data structures such as disjoint set forests and rooted minimum spanning trees.

\textbf{Appendix~\ref{chap:appendixpf}} contains my implementations of some supporting partition forest algorithms.

\textbf{Appendix~\ref{chap:appendixapps}} discusses my implementations of volume visualization and volume calculation in \emph{millipede}. Both are important real-world applications of the segmentation and feature identification work described in the rest of the thesis.

\textbf{Appendix~\ref{chap:appendixval}} discusses my implementation of validation-related tools in \emph{millipede}.

\textbf{Appendix~\ref{chap:appendixeth}} explains how the ethical issues that arise from work in medical image analysis were accounted for in this work.

\textbf{Appendix~\ref{chap:appendixlang}} contains a brief reference for the pseudo-code language I have used in listings throughout this thesis.
