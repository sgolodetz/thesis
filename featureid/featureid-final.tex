\chapter{Identifying Features using IPFs}
\label{chap:featureid}

\vspace{-\baselineskip}

%##################################################################################################
\section{Chapter Overview}
%##################################################################################################

In the previous chapter, we saw how to construct image partition forests from medical images using the watershed and waterfall transforms from mathematical morphology. This chapter now illustrates how these partition forests can be used when attempting to automatically identify features in abdominal CT scans.

Before looking at how to identify specific features in detail, I first describe a few techniques that can be used when constructing new feature identifiers. These range from simple node filtering to more novel methods such as \emph{stratified region growing}. I then describe two different classes of feature identifier: (1) those that identify features in 2D axial (X-Y) CT slices, as were implemented in my trial system, \emph{centipede}, and described in papers such as \cite{gvccimi08} and \cite{gvcispa09}, and (2) those that identify features in 3D CT volumes, as have been implemented in my final system, \emph{millipede}. (The approaches needed in the two cases have a certain amount in common, but differ in the details: for instance, when identifying the spine in 3D volumes, it is possible to use the property that it is a feature that extends through all the axial slices. This is quite powerful, since few 3D regions will do so. The same approach evidently cannot be used in 2D, since there is only one slice.)

This lays the foundation for Chapter~\ref{chap:validation}, in which the 3D identifiers used in \emph{millipede} will be validated against manually-produced, `gold-standard' results to quantify their accuracy. (The same will not be done for the 2D identifiers in \emph{centipede}, as they have now been superseded by their 3D counterparts; however, the quality of the 2D spine results was categorised in \cite{gvcispa09}.)

%##################################################################################################
\section{General Techniques}
%##################################################################################################

%Owing to the fact that different features in abdominal CT scans have widely differing properties, it is difficult to construct a framework to enable new feature identifiers to be constructed in anything like a mechanical way -- in general, a certain amount of invention is still required. However, there is nevertheless a great deal of low-level commonality between different identifiers -- while they may not share the same higher-level structure, they all make use of a number of general techniques, e.g.~filtering for regions that satisfy particular properties. This section thus describes these `building blocks', as a necessary precursor to presenting the actual identification algorithms.

%################################################
\subsection{Node Filtering}
%################################################

A basic feature identification technique is to filter all the (non-pixel) regions in the partition forest for those that satisfy a particular predicate (e.g.~those that have a mean grey value in a certain range). This is extremely simple to implement (see Listing~\ref{code:featureid-techniques-branchnodefiltering}), but can yield surprisingly good results when the features of interest are represented as individual regions in the forest. In terms of computational complexity, it is also an extremely efficient approach, being linear in the number of forest nodes.

%---
\begin{stulisting}[p]
\caption{Node Filtering Implementation}
\label{code:featureid-techniques-branchnodefiltering}
\lstinputlisting[style=Default]{featureid/featureid-techniques-branchnodefiltering.lst}
\end{stulisting}
%---

The predicate used to decide whether or not a node represents a specific feature can vary in its sophistication. Simple predicates that constrain region properties such as mean grey value, size and location often work surprisingly well, as will be seen when the 3D spine identifier is described later. A slightly more involved approach is to design the predicate using a \emph{Bayesian classifier} (this was used to design the 2D ribs identifier presented in \cite{gvccimi08}). For this, we first select a subset $X_1,\ldots,X_n$ of the region properties maintained for each branch node (for instance, we might select the four properties of \emph{area}, \emph{max grey value}, \emph{mean grey value} and \emph{elongatedness}). Given, for each property $X_i$, a vector containing the probabilities of each value of $X_i$ given that a node is or is not a specific feature -- that is, given $\mathbf{P}(X_i | \textit{Feature})$ for each $X_i$ -- it is possible to calculate a probability indicating the likelihood of a given node being an instance of that feature. Letting $\mathit{feature}$ denote $\mathit{Feature} = \mathit{true}$, $\neg \mathit{feature}$ denote $\mathit{Feature} = \mathit{false}$, and $x_i$ denote an observed value of $X_i$, this probability can be calculated using the equation:
%
\[
P(\mathit{feature}|x_1,\ldots,x_n) = \frac{P(\mathit{feature}) \displaystyle \prod_i P(x_i|\mathit{feature})}{\displaystyle \sum_{f \in \{\mathit{feature},\neg \mathit{feature}\}} \left[ P(f) \displaystyle \prod_i P(x_i|f) \right]}
\]
%
That is, given specific values of the chosen properties at a given node (for instance, an area of $250$, max grey value of $180$, mean grey value of $160$ and elongatedness of $2.5$), this equation will calculate a value giving us some indication of how likely it is that that node represents an instance of the feature in which we're interested. In order to use this to construct the required \emph{boolean} (i.e.~true or false) predicate, we simply choose a threshold probability above which regions qualify as instances of the feature in question. For instance, we could decide that a region represents a rib if the calculated probability of its being a rib (given its properties) is greater than $80\%$.

To make an approach based on Bayesian classification effective, it is important that suitable input probability vectors $\mathbf{P}(X_i | \textit{Feature})$ be available. These can either be defined empirically, or derived from a training set of images. For the 2D ribs identifier that will be described later, the vectors were defined empirically due to the lack of a sufficiently large set of data for training purposes -- the results produced were fairly good, but substantial trial-and-error development work was required. A learning approach is evidently preferable if sufficient data is available, although care must be taken not to over-fit to the training set. The approach taken for the 2D ribs identifier, that of manually defining input probabilities, did not appear to yield significant advantages over simpler, non-Bayesian techniques, and (despite the relatively good results obtained) is probably not a sensible basis for constructing future identifiers. A better method for identifying ribs is described in the section on 3D identifiers.

In many ways, node filtering in general can be seen as extending \emph{thresholding} from pixels to regions, taking advantage of the fact that regions, being larger, can have more interesting properties. (For example, rather than selecting pixels whose grey value is in a certain range, we can select regions whose mean grey value is in a certain range, that are of a reasonable size and that are (say) completely contained within the left-hand half of the image.) This intuitively suggests that it should be possible to lift other pixel-level segmentation algorithms to the region level; the next subsection does just that by developing what is effectively a region-level approach to region growing.

%################################################
\subsection{Stratified Region Growing}
%################################################

In \S\ref{subsec:background-segmentation-regiongrowing}, we saw a basic implementation of a single-seed region growing algorithm. This was pixel-based -- an individual pixel was chosen as the seed, and a region was then grown from it by choosing whether to add pixels adjacent to the existing region to the selection one at a time based on their pixel properties. However, the same technique can be lifted to the region level -- a region can be chosen as the seed, with surrounding regions then added to it or not based on their region properties (generally speaking, an aggregate of the properties of their pixels).

The idea of stratified region growing is to take this region-level region growing approach and adapt it to work with image partition forests, whose nodes represent regions of an image. Rather than starting from a single seed, stratified region growing first filters the forest's branch nodes for (potentially) multiple seeds in multiple layers of the forest. It then grows a region from each seed in the adjacency graph of the seed's layer. Finally, the regions grown are unioned (e.g.~using a partition forest selection, as it is convenient to do so) to produce the result. See Listing~\ref{code:featureid-techniques-stratifiedregiongrowing} for pseudo-code, and Figure~\ref{?} for an illustration of the process.

%---
\begin{stulisting}[p]
\caption{Stratified Region Growing Implementation}
\label{code:featureid-techniques-stratifiedregiongrowing}
\lstinputlisting[style=Default]{featureid/featureid-techniques-stratifiedregiongrowing.lst}
\end{stulisting}
%---

Stratified region growing is interesting because the regions for the seeds are grown at different scales. One problem with growing regions only at the pixel level is that minor changes to the image (for instance, lowering the grey value of a small number of pixels) can dramatically affect the result. Conversely, running the process only at the level of large regions can result in fine detail being missed -- it can even be impossible to obtain a sensible result if the large regions don't match the feature. If used carefully, stratified region growing (and indeed other methods which operate at more than one scale) can mitigate these problems at least some of the time.

It should be noted that there is room for a certain amount of variation in how the technique is used in practice. For instance, the 2D spine identifier that will be described later (and was originally presented in \cite{gvcispa09}) `validates' the regions grown from individual seeds before adding them to the result. The precise workings of the algorithm itself are also open to modification -- for example, the 2D spine identifier as originally defined doesn't grow regions from seeds that have already been visited during region growing from an earlier seed (though that approach does mean that an ordering must be imposed on the seeds, which makes it difficult to parallelize). For the purposes of this dissertation, however, stratified region growing will refer specifically to the implementation described here, unless otherwise stated (in particular, the 2D spine identifier will be described explicitly as a variant of this approach).

%################################################
\subsection{Conditional Morphology}
%################################################

As originally mentioned in \S\ref{subsec:background-segmentation-morphology}, there is far more to the field of mathematical morphology than image segmentation techniques such as the watershed transform. Of particular interest for feature identification work are morphological operators such as \emph{dilation}, \emph{erosion}, \emph{opening} and \emph{closing}; closing in particular is a useful tool for filling in holes in identified features (such as those produced by region growing). The canonical formulation of these processes is as operators on binary or grey-scale images, but of more relevance for our purposes is their adaptation to graphs (e.g.~see \cite{heijmans92a}), since the partition forest is essentially a graph hierarchy. We therefore examine only graph-based morphological operators here -- interested readers are encouraged to consult \cite{gonzalez02} for a description of their more conventional, image-based equivalents.

Image-based morphological operators are often defined in terms of a tiny shape called a \emph{structuring element}, for example a $3 \times 3$ square, but non-structured versions are also possible. For graphs, non-structured operators were studied first, with structured operators defined in terms of \emph{structuring graphs} (the graph-based equivalent of structuring elements) introduced later in \cite{heijmans92a}. However, for the feature identification algorithms described in this chapter, the non-structured operators were considered appropriate. As will be described later, the versions we use in practice are actually parameterised by user-specified conditions that control how the process works, but the non-conditional versions will be presented first for the purposes of explication.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Non-Structured Dilation}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The first morphological graph operator we will examine, then, is non-structured dilation. Given an undirected graph $G = (V,E)$ and a set $S \subseteq V$ of selected nodes, the \emph{elementary} non-structured dilation of $S$, which we will write as $\delta(S)$ to follow the convention given in \cite{heijmans92a}, is defined as:
%
\[
\delta(S) = S \cup \{v \in V \; | \; \exists u \in S \cdot \{v,u\} \in E\}
\]
%
In other words, performing an elementary non-structured dilation on a set $S$ of selected nodes means augmenting the selection with those nodes that are directly adjacent to nodes in $S$. This is illustrated in Figure~\ref{fig:featureid-techniques-dilation}.

%---
\begin{stusubfig}{p}
	\subfigure[The initial selection]
	{\includegraphics[height=8cm]{featureid/featureid-techniques-dilation-a.png}}%
	%
	\hspace{12mm}%
	%
	\subfigure[After dilating]
	{\includegraphics[height=8cm]{featureid/featureid-techniques-dilation-b.png}}%
\caption{Elementary non-structured morphological dilation on graphs: the black nodes are those initially selected and the blue nodes are those added by the dilation.}
\label{fig:featureid-techniques-dilation}
\end{stusubfig}
%---

As described in \cite{heijmans92a}, several elementary non-structured dilations can also be chained together to give the size $n$ non-structured dilation of $S$:
%
\[
\delta^{(n)}(S) = (\underbrace{\delta \bullet \delta \bullet \cdots \bullet \delta}_{n \mbox{ times}})(S)
\]
%
As with the image-based dilation described in \cite{gonzalez02}, graph-based dilation is useful for gap bridging and, to a certain extent, hole filling. Dilations of larger sizes can be used to bridge wider gaps or fill larger holes. However, because it works by expanding boundaries, dilation makes the selection as a whole grow -- whilst it can be used to fill internal holes, it achieves this in a way that drastically changes the size of the overall selection. The closing operator (described later) avoids this problem by first performing a dilation, and then eroding the result. This yields much better results for hole filling.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Non-Structured Erosion}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The counterpart of non-structured dilation is non-structured erosion. Given an undirected graph and set $S$ as defined above, the \emph{elementary} non-structured erosion of $S$ is:
%
\[
\epsilon(S) = \{v \in S \; | \; \not\exists u \in V \; \backslash \; S \cdot \{v,u\} \in E\}
\]
%
That is, performing an elementary non-structured erosion on $S$ means removing all the boundary nodes from $S$. This is illustrated in Figure~\ref{fig:featureid-techniques-erosion}.

%---
\begin{stusubfig}{p}
	\subfigure[The initial selection]
	{\includegraphics[height=8cm]{featureid/featureid-techniques-erosion-a.png}\hspace{12mm}}%
	%
	\hspace{4mm}%
	%
	\subfigure[After eroding]
	{\includegraphics[height=8cm]{featureid/featureid-techniques-erosion-b.png}}%
\caption{Elementary non-structured morphological erosion on graphs: the black nodes are those initially selected and the red nodes are those removed by the erosion.}
\label{fig:featureid-techniques-erosion}
\end{stusubfig}
%---

As with dilation, several elementary non-structured erosions can be chained together to give the size $n$ non-structured erosion of $S$:
%
\[
\epsilon^{(n)}(S) = (\underbrace{\epsilon \bullet \epsilon \bullet \cdots \bullet \epsilon}_{n \mbox{ times}})(S)
\]
%
As with the image-based erosion described in \cite{gonzalez02}, graph-based erosion is a useful tool to remove small, irrelevant pieces from the selection. Erosions of larger sizes can be used to remove larger pieces. As with dilation, however, erosion seriously affects the size of the overall selection. Whilst this has its uses, there are applications for which the goal is to improve the existing selection without changing its extent too much. For such applications, the higher-level opening and closing operators described next tend to be more useful than dilation and erosion.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Non-Structured Opening}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The non-structured opening operator of size $n$ first erodes $S$ and then dilates the result:
%
\[
\sigma^{(n)} = \delta^{(n)} \bullet \epsilon^{(n)}
\]
%
The intuition is that this starts by removing small, irrelevant pieces and making larger pieces smaller, and then roughly restores the larger pieces to their original size again (this isn't strictly true, since information is lost when the larger pieces are eroded, but it is a useful way of thinking about it). The way opening works is illustrated in Figure~\ref{?}.

As with the image-based opening described in \cite{gonzalez02}, graph-based opening is useful for things like removing narrow connections between larger pieces of the selection. Somewhat wider connections can be removed by opening with a larger size, but this runs the risk of adversely affecting the rest of the selection.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Non-Structured Closing}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The counterpart of non-structured opening is non-structured closing. The non-structured closing operator of size $n$ first dilates $S$ and then erodes the result:
%
\[
\kappa^{(n)} = \epsilon^{(n)} \bullet \delta^{(n)}
\]
%
The intuition is that this starts by expanding the boundaries of the selection (including internal boundaries, which fills in holes) and then erodes the remaining boundaries (which we hope are the outer ones) to return the selection to something like its original size (again, this isn't strictly true, but it gives a rough guide to what is happening). The way closing works is illustrated in Figure~\ref{?}.

Closing is a good tool for filling in holes. Larger holes can be filled in by closing with a larger size, but care must again be taken to avoid damaging the rest of the selection.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsubsection{Conditioning}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The operators as described thus far are useful, but can be quite blunt instruments. For example, dilation takes no account of what is beyond the boundaries when expanding the selection, so it can be difficult to avoid damaging the outer boundary of the selection when trying to fill holes (see Figure~\ref{?}(b)). Better results (see Figure~\ref{?}(c)) can be obtained by allowing the user to specify \emph{conditions} that determine when to allow dilation into or erosion of a graph node, e.g.~that a node beyond the boundary should only be added to the selection during dilation if its mean grey value lies in a particular range. This approach is known (for obvious reasons) as \emph{conditional morphology}; implementations of the conditional morphological operators are shown in Listing~\ref{code:featureid-techniques-conditionalmorphology}. These are the operators that we will use in practice when implementing the 3D feature identifiers described later.

%---
\begin{stulisting}[p]
\caption{Implementation of Conditional Morphological Operators}
\label{code:featureid-techniques-conditionalmorphology}
\lstinputlisting[style=Default]{featureid/featureid-techniques-conditionalmorphology.lst}
\end{stulisting}
%---

%################################################
\subsection{Connected Component Analysis}
%################################################

When identifying features, it is sometimes useful to work with the connected components of an intermediate feature selection. For instance, it will be seen later that the 3D ribs identifier first uses stratified region growing to produce an initial selection for the ribs, and then post-processes it, examining each connected component to see how rib-like it is.

Given a set of nodes in a particular layer of the partition forest, it is clearly a simple process to determine their connected components for such processing (see Appendix~\ref{chap:appendixpf} for pseudo-code). However, partition forest selections have a representation that is multi-layer (see Chapter~\ref{chap:ipfs}) -- it is therefore necessary to view the selection at a particular layer so as to ensure that all the nodes being dealt with are at the same level, namely the lowest layer containing a selected node. As explained when it was described, the view at layer algorithm splits higher-level nodes into their descendants in the chosen layer, whilst leaving lower-level nodes alone. The result in this case is thus a set of nodes in a single layer. The connected components of these nodes (and the properties of each component) can then be easily determined.

%##################################################################################################
\section{Feature Identification in Axial Slices}
%##################################################################################################

TODO

%##################################################################################################
\section{Feature Identification in 3D Volumes}
%##################################################################################################

TODO

%---
\begin{stulisting}[p]
\caption{Spine Identification in 3D}
\label{code:featureid-3d-spineidentification}
\lstinputlisting[style=Default]{featureid/featureid-3d-spineidentification.lst}
\end{stulisting}
%---

%---
\begin{stulisting}[p]
\caption{Spinal Cord Identification in 3D}
\label{code:featureid-3d-spinalcordidentification}
\lstinputlisting[style=Default]{featureid/featureid-3d-spinalcordidentification.lst}
\end{stulisting}
%---

%##################################################################################################
\section{Chapter Summary}
%##################################################################################################

TODO
